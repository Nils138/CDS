{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eabe81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b2555c",
   "metadata": {},
   "source": [
    "# Perceptron ex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06fb226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.3368 0.0478\n",
      "6.242460659894561 0.0608\n",
      "3.675748074395236 -0.023\n",
      "0.9926596808685032 0.0652\n",
      "0.5517816148790473 0.0618\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(37)\n",
    "\n",
    "def get_data(N, P):\n",
    "    \"\"\"\n",
    "    Creates data, initial weights, and corresponding labels\n",
    "    \n",
    "    Parameters:\n",
    "    N : number of samples\n",
    "    P : number of patterns\n",
    "    \n",
    "    Returns:\n",
    "    xi : np matrix size (N, P), binary -1 or 1\n",
    "    w0 : np matrix size (1, N), normally distributed\n",
    "    labels : list length P, indicating the truth labels of xi * w0\n",
    "    \"\"\"\n",
    "    xi = np.random.choice([0, 1], size=(N, P))\n",
    "    xi[xi==0] = -1\n",
    "    \n",
    "    w0 = np.random.randn(1, N)\n",
    "    labels = []\n",
    "    for j in range(P):\n",
    "        labels.append(np.sign(xi[:,j] * w0))\n",
    "        \n",
    "    return xi, w0, labels\n",
    "\n",
    "\n",
    "def train(x, w0, eta=0.01, n_epoch=100):\n",
    "    \"\"\"Trains the perceptron\n",
    "    \n",
    "    Parameters:\n",
    "    x : input data, size (N, P)\n",
    "    w0 : initial weights, size (1, N)\n",
    "    n_epoch : number of iterations to train for\n",
    "    \n",
    "    Returns:\n",
    "    w : weight parameters after training such that \n",
    "    \"\"\"\n",
    "    w = w0\n",
    "    for epoch in range(n_epoch):\n",
    "        labels = np.sign(np.dot(x.T, w.T))\n",
    "        update_idxs = np.equal(labels, -1) + np.equal(labels, 0)\n",
    "        if np.all(update_idxs == 0):\n",
    "            return w\n",
    "        else:\n",
    "            w = w + eta * np.sum(np.multiply(x.T, update_idxs).T, axis=1)\n",
    "    return w\n",
    "\n",
    "def error(N, P):\n",
    "    \"\"\"Calculates the error according to the derived formula in (a)\"\"\"\n",
    "    return 8/P * (5.991 + N * (1.693 + math.log(P) - math.log(N)))\n",
    "\n",
    "def numerical_error(x, w, y):\n",
    "    \"\"\"Calculates the numerical error according to the test set\"\"\"\n",
    "    preds = np.multiply(x.T, w).T\n",
    "    return np.sum(y) / preds.shape[1]\n",
    "    \n",
    "N = 10\n",
    "Ps = [10, 50, 100, 500, 1000]\n",
    "\n",
    "# Hyperparams\n",
    "n_learning_runs = 100\n",
    "eta = 0.01\n",
    "\n",
    "for P in Ps:\n",
    "    # Get data\n",
    "    train_xi, train_w0, train_labels = get_data(N, P)\n",
    "    test_xi, test_w, test_labels = get_data(N, 10000) \n",
    "    \n",
    "    # Train weights\n",
    "    w = train(train_xi, train_w0, eta, n_learning_runs)\n",
    "    \n",
    "    # Obtain bound + error on test set\n",
    "    epsilon = error(N, P)\n",
    "    ner = numerical_error(test_xi, test_w, test_labels)\n",
    "    print(epsilon, ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac71500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
